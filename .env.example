# Authentication - Only one API key is required based on your preferred model
GITHUB_TOKEN=your-github-token-here           # For DeepSeek (free with GitHub account) - needs models:read scope
OPENROUTER_API_KEY=your-openrouter-api-key-here  # For Perplexity (free tier available)

# LLM Provider Selection
USE_PERPLEXITY=false  # Set to 'true' to use Perplexity, 'false' to use DeepSeek

# DeepSeek Configuration (used when USE_PERPLEXITY=false)
DEEPSEEK_ENDPOINT=https://models.inference.ai.azure.com
DEEPSEEK_MODEL=DeepSeek-V3

# Perplexity Configuration (used when USE_PERPLEXITY=true or with --research flag)
PERPLEXITY_MODEL=perplexity/sonar  # Free tier model via OpenRouter
SITE_URL=https://your-site-url.com  # For OpenRouter attribution (can be placeholder)
SITE_NAME=Task Master AI            # For OpenRouter attribution (can be placeholder)

# Common Model Configuration
MAX_TOKENS=500   # Lower values help stay within free tier limits
TEMPERATURE=0.7  # Temperature for model responses

# App Configuration
DEBUG=false      # Set to 'true' for verbose logging

# Task Management Configuration
DEFAULT_SUBTASKS=3      # Default number of subtasks when expanding
DEFAULT_PRIORITY=medium # Default priority for generated tasks
PROJECT_NAME=Task-Master # Project name for tasks.json metadata 